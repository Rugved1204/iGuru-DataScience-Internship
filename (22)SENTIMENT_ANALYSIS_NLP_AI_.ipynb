{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpEusHfKjpL7",
        "outputId": "0545cf9b-a84e-4db0-cdbd-22e88bd47f05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization breaks the raw text into words, sentences called token\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize"
      ],
      "metadata": {
        "id": "9zpbumHql5gU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'Best quality, Great sound, Good comfort with superb Headphone Design.'\n",
        "word_tokenize(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2wu-Gh2mQUU",
        "outputId": "cff1f040-ff7b-4405-c2ef-3a1c4f156f39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Best',\n",
              " 'quality',\n",
              " ',',\n",
              " 'Great',\n",
              " 'sound',\n",
              " ',',\n",
              " 'Good',\n",
              " 'comfort',\n",
              " 'with',\n",
              " 'superb',\n",
              " 'Headphone',\n",
              " 'Design',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'Buying gold is considered auspicious on weddings, religious rituals, and special occasions. This is the reason why, even though the government and the Reserve Bank of India (RBI) introduced schemes like sovereign gold bonds, people remained inclined towards physical gold.People not only like to wear it as jewellery, but also consider it a safe investment that can be sold when needed. This is the reason why tonnes of gold are bought every year in the Indian market, and people’s interest in it never fades.'\n",
        "sent_tokenize(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G16bEslwnx_A",
        "outputId": "07408ae4-90df-40a7-abfd-8c7ed7c13cea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Buying gold is considered auspicious on weddings, religious rituals, and special occasions.',\n",
              " 'This is the reason why, even though the government and the Reserve Bank of India (RBI) introduced schemes like sovereign gold bonds, people remained inclined towards physical gold.People not only like to wear it as jewellery, but also consider it a safe investment that can be sold when needed.',\n",
              " 'This is the reason why tonnes of gold are bought every year in the Indian market, and people’s interest in it never fades.']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# split()\n",
        "text = 'Best quality, Great sound, Good comfort with superb Headphone Design.'\n",
        "text.split()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPaL04z0n9RA",
        "outputId": "5e5c7a01-9bca-4685-da0c-1199332495be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Best',\n",
              " 'quality,',\n",
              " 'Great',\n",
              " 'sound,',\n",
              " 'Good',\n",
              " 'comfort',\n",
              " 'with',\n",
              " 'superb',\n",
              " 'Headphone',\n",
              " 'Design.']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# filtering stop words\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0CXxjybyn-wU",
        "outputId": "ac4298e3-3fb8-4d95-9193-f7c5967f9dfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "stopwords = stopwords.words('english')"
      ],
      "metadata": {
        "id": "bwJ6fDUaqFbA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'Best quality, great sound, Good comfort with superb Headphone Design.'\n",
        "words = word_tokenize(text)"
      ],
      "metadata": {
        "id": "T4zts1_2qGUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_list = []\n",
        "for word in words:\n",
        "    if word.casefold() not in stopwords:\n",
        "        filtered_list.append(word)\n",
        "filtered_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4k6tlinrIIL",
        "outputId": "650523a1-a020-4afd-9467-1c2742329d16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Best',\n",
              " 'quality',\n",
              " ',',\n",
              " 'Great',\n",
              " 'sound',\n",
              " ',',\n",
              " 'Good',\n",
              " 'comfort',\n",
              " 'superb',\n",
              " 'Headphone',\n",
              " 'Design',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_list = []\n",
        "for word in words:\n",
        "    if word.casefold() not in stopwords:\n",
        "        filtered_list.append(word)\n",
        "filtered_list"
      ],
      "metadata": {
        "id": "y4ixdPHVr1OO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_list = [word for word in words if word.casefold() not in stopwords]\n",
        "filtered_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYu6vAswrPUy",
        "outputId": "d03015ef-b7c9-48bc-b147-8a5b26b0abc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Best',\n",
              " 'quality',\n",
              " ',',\n",
              " 'great',\n",
              " 'sound',\n",
              " ',',\n",
              " 'Good',\n",
              " 'comfort',\n",
              " 'superb',\n",
              " 'Headphone',\n",
              " 'Design',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stemming - keep only stem part of word and discard anything else\n",
        "from nltk.stem import PorterStemmer\n",
        "ps = PorterStemmer()\n",
        "word = ['playing', 'plays', 'played', 'player']\n",
        "for w in word:\n",
        "    print(ps.stem(w))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZwPU4hKsE6S",
        "outputId": "56527b4e-2d33-4548-811f-0c70e77932e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "play\n",
            "play\n",
            "play\n",
            "player\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-0m9f_pt3x7",
        "outputId": "bb6542b8-ac04-41e1-98d1-d0ec96e66a1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lemmatizer - keep only stem part of word and discard anything else\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "word = ['playing', 'plays', 'played', 'player']\n",
        "for w in word:\n",
        "    print(lemmatizer.lemmatize(w))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mR8EPAktZ4P",
        "outputId": "387ccd5c-4f03-4c6d-89a9-e474ef098fae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "playing\n",
            "play\n",
            "played\n",
            "player\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lemmatization vs. Stemming: Key Differences\n",
        "# Lemmatization: Converts words to their base or dictionary form (lemma).\n",
        "# Stemming: Reduces words to their root form (stem), which may not be a valid word."
      ],
      "metadata": {
        "id": "qC-COWEnumGh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = ['Discovery', 'discover', 'discoveries', 'discovering']\n",
        "for word in words:\n",
        "    print(lemmatizer.lemmatize(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0AIXS8gYu0WT",
        "outputId": "784aab70-9e99-4a27-e768-ccafe98d5ba7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discovery\n",
            "discover\n",
            "discovery\n",
            "discovering\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = ['Discovery', 'discover', 'discoveries', 'discovering']\n",
        "for word in words:\n",
        "    print(ps.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJ94TnA0u2x7",
        "outputId": "f53666ed-8bb6-4b5c-81d4-10e6837b8749"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "discoveri\n",
            "discov\n",
            "discoveri\n",
            "discov\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Part-of-speech tagging [pos tagging] -- mark each word as noun, adjective, etc\n",
        "#\n",
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('averaged_perceptron_tagger_eng')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwyk1FUevR4X",
        "outputId": "71cb26bd-7b58-4be4-f655-998fc4dd3773"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'the quick brown fox jumps over the little lazy dog'\n",
        "words = word_tokenize(text)\n",
        "nltk.pos_tag(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dsvrik_5wqUX",
        "outputId": "310d7ebf-2259-47c8-a7b5-59328138cbee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('the', 'DT'),\n",
              " ('quick', 'JJ'),\n",
              " ('brown', 'NN'),\n",
              " ('fox', 'NN'),\n",
              " ('jumps', 'VBZ'),\n",
              " ('over', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('little', 'JJ'),\n",
              " ('lazy', 'JJ'),\n",
              " ('dog', 'NN')]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TextBlob.correct() method\n",
        "# will correct the spelling mistakes, but the % is not that high\n",
        "from textblob import TextBlob\n",
        "text = TextBlob('I havv goood speling!')\n",
        "text.correct()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCgNqVzPxWtd",
        "outputId": "344dc189-fe91-4060-b163-1ba14020bbfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TextBlob(\"I have good spelling!\")"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = TextBlob('XYZ is a good compny and alays valule ttheir employees.')\n",
        "test = test.correct()\n",
        "print(test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4SV2wb7xuma",
        "outputId": "ac1c6229-9611-4fec-befc-7f1455131f19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XYZ is a good company and always value their employees.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install googletrans"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h53qlWIiyFii",
        "outputId": "aeccac84-a15e-472d-9650-ac8afbe61605"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting googletrans\n",
            "  Downloading googletrans-4.0.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: httpx>=0.27.2 in /usr/local/lib/python3.11/dist-packages (from httpx[http2]>=0.27.2->googletrans) (0.28.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (0.14.0)\n",
            "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.11/dist-packages (from httpx[http2]>=0.27.2->googletrans) (4.2.0)\n",
            "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]>=0.27.2->googletrans) (6.1.0)\n",
            "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]>=0.27.2->googletrans) (4.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (1.3.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (4.13.0)\n",
            "Downloading googletrans-4.0.2-py3-none-any.whl (18 kB)\n",
            "Installing collected packages: googletrans\n",
            "Successfully installed googletrans-4.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import googletrans\n",
        "googletrans.LANGUAGES"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-o2DvofyNtc",
        "outputId": "f3fc39a0-e178-4370-9b1f-4dd822547162"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'abk': 'abkhaz',\n",
              " 'ace': 'acehnese',\n",
              " 'ach': 'acholi',\n",
              " 'aar': 'afar',\n",
              " 'af': 'afrikaans',\n",
              " 'sq': 'albanian',\n",
              " 'alz': 'alur',\n",
              " 'am': 'amharic',\n",
              " 'ar': 'arabic',\n",
              " 'hy': 'armenian',\n",
              " 'as': 'assamese',\n",
              " 'ava': 'avar',\n",
              " 'awa': 'awadhi',\n",
              " 'ay': 'aymara',\n",
              " 'az': 'azerbaijani',\n",
              " 'ban': 'balinese',\n",
              " 'bal': 'baluchi',\n",
              " 'bm': 'bambara',\n",
              " 'bci': 'baoulé',\n",
              " 'bak': 'bashkir',\n",
              " 'eu': 'basque',\n",
              " 'btx': 'batak karo',\n",
              " 'bts': 'batak simalungun',\n",
              " 'bbc': 'batak toba',\n",
              " 'be': 'belarusian',\n",
              " 'bem': 'bemba',\n",
              " 'bn': 'bengali',\n",
              " 'bew': 'betawi',\n",
              " 'bho': 'bhojpuri',\n",
              " 'bik': 'bikol',\n",
              " 'bs': 'bosnian',\n",
              " 'bre': 'breton',\n",
              " 'bg': 'bulgarian',\n",
              " 'bua': 'buryat',\n",
              " 'yue': 'cantonese',\n",
              " 'ca': 'catalan',\n",
              " 'ceb': 'cebuano',\n",
              " 'cha': 'chamorro',\n",
              " 'che': 'chechen',\n",
              " 'zh': 'chinese',\n",
              " 'zh-cn': 'chinese (simplified)',\n",
              " 'zh-tw': 'chinese (traditional)',\n",
              " 'chk': 'chuukese',\n",
              " 'chv': 'chuvash',\n",
              " 'co': 'corsican',\n",
              " 'crh': 'crimean tatar',\n",
              " 'hr': 'croatian',\n",
              " 'cs': 'czech',\n",
              " 'da': 'danish',\n",
              " 'fa-af': 'dari',\n",
              " 'dv': 'dhivehi',\n",
              " 'din': 'dinka',\n",
              " 'doi': 'dogri',\n",
              " 'dom': 'dombe',\n",
              " 'nl': 'dutch',\n",
              " 'dyu': 'dyula',\n",
              " 'dzo': 'dzongkha',\n",
              " 'en': 'english',\n",
              " 'eo': 'esperanto',\n",
              " 'et': 'estonian',\n",
              " 'fao': 'faroese',\n",
              " 'fij': 'fijian',\n",
              " 'fil': 'filipino (tagalog)',\n",
              " 'fi': 'finnish',\n",
              " 'fon': 'fon',\n",
              " 'fr': 'french',\n",
              " 'fy': 'frisian',\n",
              " 'fur': 'friulian',\n",
              " 'ful': 'fulani',\n",
              " 'gaa': 'ga',\n",
              " 'gl': 'galician',\n",
              " 'ka': 'georgian',\n",
              " 'de': 'german',\n",
              " 'el': 'greek',\n",
              " 'gn': 'guarani',\n",
              " 'gu': 'gujarati',\n",
              " 'ht': 'haitian creole',\n",
              " 'cnh': 'hakha chin',\n",
              " 'ha': 'hausa',\n",
              " 'haw': 'hawaiian',\n",
              " 'he': 'hebrew',\n",
              " 'iw': 'hebrew',\n",
              " 'hil': 'hiligaynon',\n",
              " 'hi': 'hindi',\n",
              " 'hmn': 'hmong',\n",
              " 'hu': 'hungarian',\n",
              " 'hrx': 'hunsrik',\n",
              " 'iba': 'iban',\n",
              " 'is': 'icelandic',\n",
              " 'ig': 'igbo',\n",
              " 'ilo': 'ilocano',\n",
              " 'id': 'indonesian',\n",
              " 'ga': 'irish',\n",
              " 'it': 'italian',\n",
              " 'jam': 'jamaican patois',\n",
              " 'ja': 'japanese',\n",
              " 'jv': 'javanese',\n",
              " 'jw': 'javanese',\n",
              " 'kac': 'jingpo',\n",
              " 'kal': 'kalaallisut',\n",
              " 'kn': 'kannada',\n",
              " 'kau': 'kanuri',\n",
              " 'pam': 'kapampangan',\n",
              " 'kk': 'kazakh',\n",
              " 'kha': 'khasi',\n",
              " 'km': 'khmer',\n",
              " 'cgg': 'kiga',\n",
              " 'kik': 'kikongo',\n",
              " 'rw': 'kinyarwanda',\n",
              " 'ktu': 'kituba',\n",
              " 'trp': 'kokborok',\n",
              " 'kom': 'komi',\n",
              " 'gom': 'konkani',\n",
              " 'ko': 'korean',\n",
              " 'kri': 'krio',\n",
              " 'ku': 'kurdish',\n",
              " 'ckb': 'kurdish (sorani)',\n",
              " 'ky': 'kyrgyz',\n",
              " 'lo': 'lao',\n",
              " 'ltg': 'latgalian',\n",
              " 'la': 'latin',\n",
              " 'lv': 'latvian',\n",
              " 'lij': 'ligurian',\n",
              " 'lim': 'limburgish',\n",
              " 'ln': 'lingala',\n",
              " 'lt': 'lithuanian',\n",
              " 'lmo': 'lombard',\n",
              " 'lg': 'luganda',\n",
              " 'luo': 'luo',\n",
              " 'lb': 'luxembourgish',\n",
              " 'mk': 'macedonian',\n",
              " 'mad': 'madurese',\n",
              " 'mai': 'maithili',\n",
              " 'mak': 'makassar',\n",
              " 'mg': 'malagasy',\n",
              " 'ms': 'malay',\n",
              " 'ms-arab': 'malay (jawi)',\n",
              " 'ml': 'malayalam',\n",
              " 'mt': 'maltese',\n",
              " 'mam': 'mam',\n",
              " 'glv': 'manx',\n",
              " 'mi': 'maori',\n",
              " 'mr': 'marathi',\n",
              " 'mah': 'marshallese',\n",
              " 'mwr': 'marwadi',\n",
              " 'mfe': 'mauritian creole',\n",
              " 'mhr': 'meadow mari',\n",
              " 'mni-mtei': 'meiteilon (manipuri)',\n",
              " 'min': 'minang',\n",
              " 'lus': 'mizo',\n",
              " 'mn': 'mongolian',\n",
              " 'my': 'myanmar (burmese)',\n",
              " 'nhe': 'nahuatl (eastern huasteca)',\n",
              " 'ndc-zw': 'ndau',\n",
              " 'nde': 'ndebele (south)',\n",
              " 'new': 'nepalbhasa (newari)',\n",
              " 'ne': 'nepali',\n",
              " 'no': 'norwegian',\n",
              " 'nus': 'nuer',\n",
              " 'ny': 'nyanja (chichewa)',\n",
              " 'oci': 'occitan',\n",
              " 'or': 'odia (oriya)',\n",
              " 'om': 'oromo',\n",
              " 'oss': 'ossetian',\n",
              " 'pag': 'pangasinan',\n",
              " 'pap': 'papiamento',\n",
              " 'ps': 'pashto',\n",
              " 'fa': 'persian',\n",
              " 'pl': 'polish',\n",
              " 'por': 'portuguese (portugal)',\n",
              " 'pt': 'portuguese (portugal, brazil)',\n",
              " 'pa': 'punjabi',\n",
              " 'pa-arab': 'punjabi (shahmukhi)',\n",
              " 'kek': \"q'eqchi'\",\n",
              " 'qu': 'quechua',\n",
              " 'rom': 'romani',\n",
              " 'ro': 'romanian',\n",
              " 'run': 'rundi',\n",
              " 'ru': 'russian',\n",
              " 'sme': 'sami (north)',\n",
              " 'sm': 'samoan',\n",
              " 'sag': 'sango',\n",
              " 'sa': 'sanskrit',\n",
              " 'sat': 'santali',\n",
              " 'gd': 'scots gaelic',\n",
              " 'nso': 'sepedi',\n",
              " 'sr': 'serbian',\n",
              " 'st': 'sesotho',\n",
              " 'crs': 'seychellois creole',\n",
              " 'shn': 'shan',\n",
              " 'sn': 'shona',\n",
              " 'scn': 'sicilian',\n",
              " 'szl': 'silesian',\n",
              " 'sd': 'sindhi',\n",
              " 'si': 'sinhala (sinhalese)',\n",
              " 'sk': 'slovak',\n",
              " 'sl': 'slovenian',\n",
              " 'so': 'somali',\n",
              " 'es': 'spanish',\n",
              " 'su': 'sundanese',\n",
              " 'sus': 'susu',\n",
              " 'sw': 'swahili',\n",
              " 'ssw': 'swati',\n",
              " 'sv': 'swedish',\n",
              " 'tl': 'tagalog (filipino)',\n",
              " 'tah': 'tahitian',\n",
              " 'tg': 'tajik',\n",
              " 'ber-atn': 'tamazight',\n",
              " 'ber': 'tamazight (tifinagh)',\n",
              " 'ta': 'tamil',\n",
              " 'tt': 'tatar',\n",
              " 'te': 'telugu',\n",
              " 'tet': 'tetum',\n",
              " 'th': 'thai',\n",
              " 'bod': 'tibetan',\n",
              " 'ti': 'tigrinya',\n",
              " 'tiv': 'tiv',\n",
              " 'tpi': 'tok pisin',\n",
              " 'ton': 'tongan',\n",
              " 'ts': 'tsonga',\n",
              " 'tsn': 'tswana',\n",
              " 'tcy': 'tulu',\n",
              " 'tum': 'tumbuka',\n",
              " 'tr': 'turkish',\n",
              " 'tk': 'turkmen',\n",
              " 'tuk': 'tuvan',\n",
              " 'ak': 'twi (akan)',\n",
              " 'udm': 'udmurt',\n",
              " 'uk': 'ukrainian',\n",
              " 'ur': 'urdu',\n",
              " 'ug': 'uyghur',\n",
              " 'uz': 'uzbek',\n",
              " 'ven': 'venda',\n",
              " 'vec': 'venetian',\n",
              " 'vi': 'vietnamese',\n",
              " 'war': 'waray',\n",
              " 'cy': 'welsh',\n",
              " 'wol': 'wolof',\n",
              " 'xh': 'xhosa',\n",
              " 'sah': 'yakut',\n",
              " 'yi': 'yiddish',\n",
              " 'yo': 'yoruba',\n",
              " 'yua': 'yucatec maya',\n",
              " 'zap': 'zapotec',\n",
              " 'zu': 'zulu'}"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from googletrans import Translator\n",
        "translator = Translator()"
      ],
      "metadata": {
        "id": "DWMpDdqSzgoC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from_lang =  'th'\n",
        "to_lang = 'en'\n",
        "text = 'อรุณสวัสดิ์'\n",
        "res = await translator.translate(text, src=from_lang, dest=to_lang)\n",
        "print(res.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CFc4kcyz1T3",
        "outputId": "e41ade47-3ec5-491c-a61c-c6f9ef64d829"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "good morning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langdetect\n",
        "from langdetect import detect\n",
        "detect('อรุณสวัสดิ์')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "DaU24sDM0QuH",
        "outputId": "67a896d4-16eb-4b35-cd5f-02c7fb49939e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.11/dist-packages (1.0.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from langdetect) (1.17.0)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'th'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langdetect import detect_langs\n",
        "detect_langs('Wie gehts?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6WWQBh82ato",
        "outputId": "10fee066-a217-4efa-8bb0-eb46ec2c202c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[de:0.9999953575421194]"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SENTIMENT ANALYSIS\n",
        "import nltk\n",
        "nltk.download('vader_lexicon')"
      ],
      "metadata": {
        "id": "RiF16gan2ojE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdb3c5b6-edb2-438c-f574-9d225bcd285b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "sid = SentimentIntensityAnalyzer()"
      ],
      "metadata": {
        "id": "duQCoV0-43X2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"The movie was amazing. I loved i badly\"\n",
        "score = sid.polarity_scores(text)\n",
        "print(score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFodOces5X7T",
        "outputId": "d9733579-4dd1-47e0-e625-bca0f50b7474"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'neg': 0.225, 'neu': 0.217, 'pos': 0.558, 'compound': 0.6808}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'i am watching a movie'\n",
        "score = sid.polarity_scores(text)\n",
        "print(score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqMU5Rcn5n5z",
        "outputId": "c33b5f39-71a4-4f25-9c7a-fdaed66b166b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'i am having my dinner. but i is not very good'\n",
        "score = sid.polarity_scores(text)\n",
        "print(score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmoxFKkf5tne",
        "outputId": "5e627077-1bcb-43a5-e0d9-6f18ebd23995"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'neg': 0.3, 'neu': 0.7, 'pos': 0.0, 'compound': -0.5321}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts = [\n",
        "    \"I love this product! It works great and is very affordable.\",\n",
        "    \"This product is okay. It gets the job done, but could be better.\",\n",
        "    \"I hate this product. It doesn't work at all and is a waste of money.\",\n",
        "    \"I am watching a movie\"\n",
        "]\n",
        "\n",
        "def sentimentFinder(text):\n",
        "  score = sid.polarity_scores(text)\n",
        "  compound = score['compound']\n",
        "  if compound >= 0.05:\n",
        "    return 'Positive'\n",
        "  elif compound <= -0.05:\n",
        "    return 'Negative'\n",
        "  else:\n",
        "    return 'Neutral'\n",
        "\n",
        "for text in texts:\n",
        "  sentiment = sentimentFinder(text)\n",
        "  print(f\"Text: {text}\\nSentiment: {sentiment}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDmkcZ305xqL",
        "outputId": "29c3fca0-4e6b-47d3-e2f5-1b8916bb3a98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: I love this product! It works great and is very affordable.\n",
            "Sentiment: Positive\n",
            "\n",
            "Text: This product is okay. It gets the job done, but could be better.\n",
            "Sentiment: Positive\n",
            "\n",
            "Text: I hate this product. It doesn't work at all and is a waste of money.\n",
            "Sentiment: Negative\n",
            "\n",
            "Text: I am watching a movie\n",
            "Sentiment: Neutral\n",
            "\n"
          ]
        }
      ]
    }
  ]
}